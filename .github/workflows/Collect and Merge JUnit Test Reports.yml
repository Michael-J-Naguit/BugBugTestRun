name: Collect and Merge JUnit Test Reports

on:
  workflow_dispatch:
    inputs:
      workflow_name:
        description: 'Name of the workflow to collect artifacts from'
        required: true
        default: 'Run BugBug - QRA Stage Suite'

permissions:
  actions: read  # Needed to list and download artifacts
  contents: read  # Required to read repo content

jobs:
  collect-artifacts:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install jq and coreutils
        run: sudo apt-get install -y jq coreutils

      - name: List and Download Artifacts from a Specific Workflow (Last 30 Days)
        run: |
          mkdir -p all-test-results
          echo "Fetching artifacts from workflow: '${{ inputs.workflow_name }}' (last 30 days)"

          CURRENT_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          CUTOFF_DATE=$(date -u -d "30 days ago" +"%Y-%m-%dT%H:%M:%SZ")

          WORKFLOW_ID=$(gh workflow list --json id,name --jq '.[] | select(.name=="${{ inputs.workflow_name }}") | .id' --repo ${{ github.repository }})

          if [ -z "$WORKFLOW_ID" ]; then
            echo "No workflow found with the name '${{ inputs.workflow_name }}'"
            exit 1
          fi

          RUNS=$(gh run list --workflow $WORKFLOW_ID --limit 100 --json databaseId,createdAt,status \
            --jq ".[] | select(.status==\"completed\" and .createdAt >= \"$CUTOFF_DATE\") | .databaseId" \
            --repo ${{ github.repository }})

          if [ -z "$RUNS" ]; then
            echo "No completed workflow runs in the last 30 days."
            exit 0
          fi

          for RUN_ID in $RUNS; do
            echo "Downloading artifacts from workflow run: $RUN_ID"
            gh run download $RUN_ID --dir all-test-results || echo "No artifacts found for $RUN_ID"
          done
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}


      - name: Install junitparser for Merging JUnit XML
        run: pip install junitparser

      - name: Merge JUnit XML Reports
        run: |
          mkdir -p merged-results
          python - <<EOF
          from junitparser import JUnitXml, TestSuite, TestCase
      
          merged_xml = JUnitXml()
          merged_suites = TestSuite(name="Merged Test Suites")
      
          import glob
          test_files = glob.glob("all-test-results/**/*.xml", recursive=True)
      
          if not test_files:
              print("No JUnit XML files found to merge.")
              exit(1)
      
          total_tests = 0
          total_failures = 0
          total_errors = 0
          total_skipped = 0
          total_time = 0.0
      
          for file in test_files:
              print(f"Processing: {file}")
              xml = JUnitXml.fromfile(file)
      
              for suite in xml:
                  total_tests += suite.tests
                  total_failures += suite.failures
                  total_errors += suite.errors
                  total_skipped += suite.skipped
                  total_time += float(suite.time) if suite.time else 0.0
                  
                  # Append test cases individually
                  for case in suite:
                      merged_suites.add_testcase(case)
      
          # Set final counts in the merged test suite
          merged_suites.tests = total_tests
          merged_suites.failures = total_failures
          merged_suites.errors = total_errors
          merged_suites.skipped = total_skipped
          merged_suites.time = total_time
      
          merged_xml.add_testsuite(merged_suites)
      
          output_file = "merged-results/merged-test-results.xml"
          merged_xml.write(output_file)
          print(f"Merged JUnit XML report saved to: {output_file}")
          EOF
          
      - name: Upload Merged JUnit XML Report
        uses: actions/upload-artifact@v4
        with:
          name: merged-junit-test-report
          path: merged-results/merged-test-results.xml
          retention-days: 30

      - name: Install dependencies
        run: pip install junitparser matplotlib pandas plotly

      - name: Parse JUnit XML and Generate HTML Chart
        run: |
          python3 - <<EOF
          import os
          import glob
          import plotly.graph_objects as go
          from junitparser import JUnitXml, Error, Failure, Skipped, TestSuite, TestCase
      
          XML_DIR = "all-test-results"
          OUTPUT_HTML = "test-report.html"
      
          # Find the most recently modified XML file
          test_files = sorted(glob.glob(f"{XML_DIR}/**/*.xml", recursive=True), key=os.path.getmtime, reverse=True)
          if not test_files:
              print("No JUnit XML files found.")
              exit(1)
      
          # Initialize the merged results
          merged_suites = TestSuite(name="Merged Test Suites")
          passed, failed, errors, skipped = 0, 0, 0, 0
          test_case_names = []
      
          # Merge test results from all XML files
          for file in test_files:
              print(f"Processing: {file}")
              xml = JUnitXml.fromfile(file)
              
              for suite in xml:
                  for case in suite:
                      # Collect the test case names from the most recent test run
                      if os.path.abspath(file) == os.path.abspath(test_files[0]):
                          test_case_names.append(case.name)
      
                      # Merge the test cases from each file into one merged suite
                      merged_suites.add_testcase(case)
      
                      # Count the results
                      if case.result:
                          if any(isinstance(r, Failure) for r in case.result):
                              failed += 1
                          elif any(isinstance(r, Error) for r in case.result):
                              errors += 1
                          elif any(isinstance(r, Skipped) for r in case.result):
                              skipped += 1
                      else:
                          passed += 1
      
          if passed + failed + errors + skipped == 0:
              print("No test cases found. Skipping chart generation.")
              exit(0)
      
          # Create a chart based on the merged results
          statuses = ["Passed", "Failed", "Errors", "Skipped"]
          counts = [passed, failed, errors, skipped]
          colors = ['green', 'red', 'orange', 'gray']
      
          fig = go.Figure(go.Bar(
              x=counts,
              y=statuses,
              orientation='h',
              marker_color=colors,
              text=counts,
              textposition='outside'
          ))
      
          fig.update_layout(
              title="Test Status Breakdown (Merged Test Results)",
              xaxis_title="Number of Tests",
              yaxis_title="Test Status",
              xaxis=dict(
                  tickmode='linear',
                  dtick=1  # Ensures whole number ticks
              ),
              margin=dict(l=100, r=20, t=50, b=50),
              height=400
          )
      
          # Save the merged results chart as HTML
          fig.write_html(OUTPUT_HTML)
      
          # Add test case names from the latest test run below the chart in the HTML
          with open(OUTPUT_HTML, 'a') as f:
              f.write('<br><br><h3>Test Cases in Latest Run:</h3><ul style="text-align: left;">')
              for name in test_case_names:
                  f.write(f'<li>{name}</li>')  # Add each test case name as a list item
              f.write('</ul>')
      
          print(f"Test status chart saved as HTML: {OUTPUT_HTML}")
          EOF


      - name: Upload HTML Test Report
        uses: actions/upload-artifact@v4
        with:
          name: test-report
          path: test-report.html
