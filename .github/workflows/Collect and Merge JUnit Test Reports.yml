name: Collect and Merge JUnit Test Reports

on:
  workflow_dispatch:

permissions:
  actions: read  # Needed to list and download artifacts
  contents: read  # Required to read repo content

jobs:
  collect-artifacts:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install jq and coreutils
        run: sudo apt-get install -y jq coreutils

      - name: List and Download Artifacts from a Specific Workflow (Last 30 Days)
        run: |
          mkdir -p all-test-results
          echo "Fetching artifacts from workflow: My-Specific-Workflow (last 30 days)"

          # Get the current date and calculate the cutoff date (30 days ago)
          CURRENT_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          CUTOFF_DATE=$(date -u -d "30 days ago" +"%Y-%m-%dT%H:%M:%SZ")
          echo "Current Date: $CURRENT_DATE"
          echo "Cutoff Date: $CUTOFF_DATE"

          # Fetch workflow runs for the specific workflow name
          WORKFLOW_ID=$(gh workflow list --json id,name --jq '.[] | select(.name=="Run BugBug - QRA Stage Suite") | .id' --repo ${{ github.repository }})

          if [ -z "$WORKFLOW_ID" ]; then
            echo "No workflow found with the name 'Run BugBug - QRA Stage Suite'"
            exit 1
          fi

          # Get all completed runs and filter those within the last 30 days
          RUNS=$(gh run list --workflow $WORKFLOW_ID --limit 100 --json databaseId,createdAt,status \
            --jq ".[] | select(.status==\"completed\" and .createdAt >= \"$CUTOFF_DATE\") | .databaseId" \
            --repo ${{ github.repository }})

          if [ -z "$RUNS" ]; then
            echo "No completed workflow runs in the last 30 days."
            exit 0
          fi

          # Loop through each run and download artifacts
          for RUN_ID in $RUNS; do
            echo "Downloading artifacts from workflow run: $RUN_ID"
            gh run download $RUN_ID --dir all-test-results || echo "No artifacts found for $RUN_ID"
          done
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}


      - name: Install junitparser for Merging JUnit XML
        run: pip install junitparser

      - name: Merge JUnit XML Reports
        run: |
          mkdir -p merged-results
          python - <<EOF
          from junitparser import JUnitXml, TestSuite, TestCase
      
          merged_xml = JUnitXml()
          merged_suites = TestSuite(name="Merged Test Suites")
      
          import glob
          test_files = glob.glob("all-test-results/**/*.xml", recursive=True)
      
          if not test_files:
              print("No JUnit XML files found to merge.")
              exit(1)
      
          total_tests = 0
          total_failures = 0
          total_errors = 0
          total_skipped = 0
          total_time = 0.0
      
          for file in test_files:
              print(f"Processing: {file}")
              xml = JUnitXml.fromfile(file)
      
              for suite in xml:
                  total_tests += suite.tests
                  total_failures += suite.failures
                  total_errors += suite.errors
                  total_skipped += suite.skipped
                  total_time += float(suite.time) if suite.time else 0.0
                  
                  # Append test cases individually
                  for case in suite:
                      merged_suites.add_testcase(case)
      
          # Set final counts in the merged test suite
          merged_suites.tests = total_tests
          merged_suites.failures = total_failures
          merged_suites.errors = total_errors
          merged_suites.skipped = total_skipped
          merged_suites.time = total_time
      
          merged_xml.add_testsuite(merged_suites)
      
          output_file = "merged-results/merged-test-results.xml"
          merged_xml.write(output_file)
          print(f"Merged JUnit XML report saved to: {output_file}")
          EOF
          
      - name: Upload Merged JUnit XML Report
        uses: actions/upload-artifact@v4
        with:
          name: merged-junit-test-report
          path: merged-results/merged-test-results.xml
          retention-days: 30

      - name: Install dependencies
        run: pip install junitparser matplotlib pandas

      - name: Parse JUnit XML and Generate Chart
        run: |
          python3 - <<EOF
          import os
          import matplotlib.pyplot as plt
          import pandas as pd
          from junitparser import JUnitXml, Error, Failure, Skipped
          import textwrap
          
          XML_PATH = "merged-results/merged-test-results.xml"
          OUTPUT_CHART = "test_status_chart.png"
          
          # Ensure the XML file exists
          if not os.path.exists(XML_PATH):
              print(f"ERROR: JUnit XML file '{XML_PATH}' not found.")
              exit(1)
          
          # Load JUnit XML
          xml = JUnitXml.fromfile(XML_PATH)
          
          # Initialize counters
          passed, failed, errors, skipped = 0, 0, 0, 0
          unique_test_cases = set()
          
          # Process each test case
          for suite in xml:
              for case in suite:
                  unique_test_cases.add(case.name)  # Track unique test names
                  if case.result:
                      if any(isinstance(r, Failure) for r in case.result):
                          failed += 1
                      elif any(isinstance(r, Error) for r in case.result):
                          errors += 1
                      elif any(isinstance(r, Skipped) for r in case.result):
                          skipped += 1
                  else:
                      passed += 1  # No result means it passed
          
          # Check if there are test results to plot
          if passed + failed + errors + skipped == 0:
              print("No test cases found. Skipping chart generation.")
              exit(0)
          
          # Data for plotting
          statuses = ["Passed", "Failed", "Errors", "Skipped"]
          counts = [passed, failed, errors, skipped]
          colors = ['green', 'red', 'orange', 'gray']
          
          # Generate Horizontal Bar Chart
          plt.figure(figsize=(8, 5))
          plt.barh(statuses, counts, color=colors)
          plt.xlabel("Number of Tests")
          plt.ylabel("Test Status")
          plt.title("Test Status Breakdown")
          plt.xticks(rotation=45)
          
          # Display values on bars
          for index, value in enumerate(counts):
              plt.text(value, index, str(value), va='center', fontsize=10, fontweight='bold')

          # Format unique test cases text (sorted & wrapped)
          sorted_test_cases = sorted(unique_test_cases)
          wrapped_text = "\n".join(textwrap.wrap(", ".join(sorted_test_cases), width=80))
          
          # Add text below the chart
          fig.text(0.5, -0.2, f"Unique Test Cases:\n{wrapped_text}", wrap=True, horizontalalignment='center', fontsize=10)

          # Save chart with high resolution
          plt.savefig(OUTPUT_CHART, dpi=300, bbox_inches='tight')
          
          # Print summary
          print("\nTest Summary:")
          print(f"Passed: {passed}, Failed: {failed}, Errors: {errors}, Skipped: {skipped}")
          
          # Print unique test cases aligned to the left
          print("\nUnique Test Cases:")
          for test in sorted(unique_test_cases):  # Sort alphabetically for better readability
              print(f" - {test.ljust(40)}")  # Align left by padding
          
          print(f"Test status chart saved as: {OUTPUT_CHART}")
          EOF
      
      - name: Upload Test Status Chart
        uses: actions/upload-artifact@v4
        with:
          name: test-status-chart
          path: test_status_chart.png
